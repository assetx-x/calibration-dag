dcm_apis {
    dcm_base_url = ${?DCM_BASE_URL} # e.g. https://dcm-dev-gcp.dcm.ai
}
gcp {
    region = us
    region = ${?GOOGLE_REGION}
    project_id = ${GOOGLE_PROJECT_ID}
    default_dataset = marketdata
    default_dataset = ${?BQ_DEFAULT_DATASET}
}
logging {
  max_file_size = 20485760
  backup_count = 100
}
trade_publishing {
  enabled = false
  collect_metadata = true
  publishing_type = internal_comm_channel # internal_comm_channel, no_op
  publisher_topic_prefix = ""
  listener_topic_prefix = ""
  topic_prefix_separator = "-"
  kafka {
    kafka_bootstrap = [broker-1.msk:9092, broker-2.msk:9092]
    sasl_plain_username = ""
    sasl_plain_password = ""
    ssl_cafile = ""
    ssl_certfile = ""
    ssl_keyfile = ""

    kafka_bootstrap = ${?KAFKA_BOOTSTRAP}
    sasl_plain_username = ${?KAFKA_SASL_PLAIN_USERNAME}
    sasl_plain_password = ${?KAFKA_SASL_PLAIN_PASSWORD}
    ssl_cafile = ${?KAFKA_SSL_CAFILE}
    ssl_certfile = ${?KAFKA_SSL_CERTFILE}
    ssl_keyfile = ${?KAFKA_SSL_KEYFILE}
  }
  internal_comm_channel {}
}
run_description {
  git_revision = ${?GIT_REVISION}
}
ExecutionInstructions {
  DEFAULT_TIME_DELTA_IN_DAYS = 2
}
DCMTradingActor {
  topics_configuration {
    REGULAR_TOPIC {
      TOPIC_INDEX = 1
      TOPIC_SUFFIX = |
    }
    EMERGENCY_TOPIC {
      TOPIC_INDEX = 2
      TOPIC_SUFFIX = |em
    }
    DATA_UPDATE_TOPIC {
      TOPIC_INDEX = 3
      TOPIC_SUFFIX = |data
    }
  }
}
OrderFactoryIB {
  VwapParameters {
    maxPctVol = 0.05
    minimumTimeBlock = 10T
    allowPastEndTime = 1
    noTakeLiq = 0
  }
  LimitParameters {
    proportional_adjustment = 0.002
    absolute_adjustment = 0.01
  }
  FA_GROUP = "PairsTrading"
  FA_METHOD = "EqualQuantity"
  allow_orders_outside_rth = false
  use_fa_allocation = true
  AllOrNoneParameters {
    order_type = "MKT"
  }
  hedge_combo_min_share_amount = 20
}
ibpy {
  BrokerConnectionIB_client_Id = 999
  TWS_port = 7496
  BrokerConnectionIB_nextValidId_waitout_in_secs = 60
  IBConnection_time_limit_to_connect_in_seconds = 120
}
IBControllerWrapper {
  #IBController_command = /IBC/StartTWS.bat
  IBController_command = /opt/ibc/twsstart.sh
  #IBController_process_name = DisplayBannerAndLaunch.bat
  IBController_process_name = displaybannerandlaunch.sh
  IBController_waitout_sleep_time_in_secs = 30
  host = localhost
  port = 7496
}
FlexTradeOrderFactory {
  VwapParameters {
    maxPctVol = 0.05
    minimumTimeBlock = 10T
    allowPastEndTime = 1
    noTakeLiq = 0
  }
  LimitParameters {
    proportional_adjustment = 0.002
    absolute_adjustment = 0.01
  }
}
flextrade {
  oms {
    address = 172.21.84.104:50051
    # address = ${?FLEXTRADE_OMS_ADDRESS}
    instance.id = "DV"
    batch.user = "DCM"
    order.user = "DCM"
    broker = "MSCO"
    request.timeout = 5
    request.max.retries = 3
    securities {
        failed.threshold = 0.02
    }
  }
  ftp {
    host = ${?FLEXONE_HOST}
    port = 22
    user = ${?FLEXONE_SFTP_USER}
    password = ${?FLEXONE_SFTP_PWD}
    connection_timeout_min = 5
  }
}
morgan.stanley {
    locates {
        client_id = "DATACAP"
        # url = "https://sl-uat.ms.com/sltny/sltLMS/webapp/lms"
        url = "mock://"
        user = "ms_esl_fts@datacapitalmanagement.com"
        password = "Locate#2018"
        polling.interval = 60
        max.batch.size = 400
        approval.wait.duration = 1800
        quantity = 70000
    }
}
short_locates {
    shares {
        floor = 1000
        cap = 70000
        default = ${short_locates.shares.cap}

        names {
            # override per name - number of shares to request if close price is missing
            VXX = 25000
        }
    }
    notional {
        default = 200000
        BasketPairs.default = 500000
        VolatilityViews.default = 500000
        JRUnit.default = 100000
        BondMomentum.default = ${short_locates.notional.default}
        Fundamental.default = ${short_locates.notional.default}

        # override name per strategy, other strategies not affected (will be added to this amount)
        VolatilityViews.ZVZZT = 1000000

        # overrides per name regardless of strategy
        names {
            VXX = 1000000
        }
    }
    reload.interval = 300
}
reports {
    defaults {
        broker = "MSCO"
        fund = "Master"
        account_type = "Prime"
        security_type = "Equity"
        currency = "USD"
        fx_rate = 1
    }

    # <@DATE> is 20180628
    # <@SLASH_DATE> is 2018/06/28
    # <@YEAR> is 2018
    # <$config.path> will get replaced dynamically with the value of config.path when accessed

    current {
        dcm_root = "s3://dcm-production-processes/trading_reports"/<@SLASH_DATE>
        # pb_root = "s3://dcm-external-ftp/morganstanley_pb/data/SODReports"
        # Decrypted filed go here
        pb_root = ${reports.current.dcm_root}
        exec_root = "s3://dcm-external-ftp/morganstanley/data"
        fundadmin_root = "s3://dcm-external-ftp/statestreet/data/SODReports"
        oms_root = "s3://dcm-external-ftp/flextrade/data/EOD"
    }

    archive {
        common_root = "s3://dcm-production-processes/counterparties_archive"
        dcm_root = ${reports.current.dcm_root}
        # pb_root = ${reports.archive.common_root}/morganstanley/sod/<@SLASH_DATE>
        pb_root = ${reports.current.dcm_root}
        exec_root = ${reports.archive.common_root}/morganstanley/eod/<@SLASH_DATE>
        fundadmin_root = ${reports.archive.common_root}/statestreet/sod/<@SLASH_DATE>
        oms_root = ${reports.archive.common_root}/flextrade/eod/<@SLASH_DATE>
    }

    broker.sod.available_at = 4:00
    broker.sod.encryption = pgp_ms_pb
    # broker.sod.positions.location = <@pb_root>/DCM-MAC001RX-GlobalPositionsRollupExtract.<@DATE>.csv.pgp
    # broker.sod.stock_accrual.location = <@pb_root>/DCM-MAC006X-StockAccrualReport.<@DATE>.csv.pgp
    # Manually decrypt files for now:
    broker.sod.positions.location = <@pb_root>/DCM-MAC001RX-GlobalPositionsRollupExtract.<@DATE>.csv
    broker.sod.stock_accrual.location = <@pb_root>/DCM-MAC006X-StockAccrualReport.<@DATE>.csv

    broker.eod.available_at = 16:30
    broker.eod.orders.location = <@exec_root>/DCM_Order_NY_<@DATE>.csv
    broker.eod.fills.location = <@exec_root>/DCM_Fill_NY_<@DATE>.csv

    fundadmin.sod.available_at = 7:10
    fundadmin.sod.holdings.filename = "Holdings Dynamic_DCMMST_<@DATE>.csv"
    fundadmin.sod.holdings.location = <@fundadmin_root>/${reports.fundadmin.sod.holdings.filename}
    fundadmin.sod.profit_loss_ytd.filename = "Profit and Loss_DCMMST_YTD_<@YEAR>0101_<@DATE>.csv"
    fundadmin.sod.profit_loss_ytd.location = <@fundadmin_root>/${reports.fundadmin.sod.profit_loss_ytd.filename}

    oms.eod.available_at = 16:30
    oms.eod.trades_broker.location = <@oms_root>/MSPB_DCM_<@DATE><@LATEST:6>.csv
    oms.eod.trades_admin.location = <@oms_root>/DCM_StateStreet_<@DATE><@LATEST:9>.csv

    internal.sod.positions.location = <@dcm_root>/DCM_Internal_SOD_Positions_<@DATE>_<@LATEST:6>.csv
    internal.sod.positions_noca.location = <@dcm_root>/DCM_Internal_SOD_Positions_NoCA_<@DATE>_<@LATEST:6>.csv
    internal.eod.orders.location = <@dcm_root>/DCM_Internal_EOD_Trades_<@DATE>_<@LATEST:6>.csv
    internal.breaks.trades.location = <@dcm_root>/DCM_Breaks_Trades_<@DATE>_<@LATEST:6>.csv
    internal.breaks.positions.location = <@dcm_root>/DCM_Breaks_Positions_<@DATE>_<@LATEST:6>.csv

    publish.sod.positions.location = <@dcm_root>/DCM_SOD_Positions_<@DATE>_<@LATEST:6>.csv
}

DataProvider.YahooQuotesDataProvider {
  endpoint = "http://download.finance.yahoo.com/d/quotes.csv"
}
DataProvider.InteractiveBrokersEquityDataProvider {
  DataProviderFromIB_client_Id = 888
}
DataProvider.IBDataProvider {
  service_url = ${?DATA_SUBSCRIPTIONS_SERVER}/ib
  kafka_bootstrap = [broker-1.msk:9092, broker-2.msk:9092]
  sasl_plain_username = ""
  sasl_plain_password = ""
  ssl_cafile = ""
  ssl_certfile = ""
  ssl_keyfile = ""

  kafka_bootstrap = ${?KAFKA_BOOTSTRAP}
  sasl_plain_username = ${?KAFKA_SASL_PLAIN_USERNAME}
  sasl_plain_password = ${?KAFKA_SASL_PLAIN_PASSWORD}
  ssl_cafile = ${?KAFKA_SSL_CAFILE}
  ssl_certfile = ${?KAFKA_SSL_CERTFILE}
  ssl_keyfile = ${?KAFKA_SSL_KEYFILE}

  allow_use_of_past_data = true
}
#DataProvider.LiveDragonfishDataProvider {
	#endpoint = "http://52.36.34.97"
#}
DataProvider.RedshiftRavenPackDataProvider {
  redshift_user = dcm_dev
  redshift_user = ${?REDSHIFT_USER}
  redshift_pwd = pwd
  redshift_pwd = ${?REDSHIFT_PWD}
  redshift_endpoint = marketdata-test.cq0v4ljf3cuw.us-east-1.redshift.amazonaws.com
  redshift_port = 5439
  db_name = dev
  redshift_credentials = ${DataProvider.RedshiftRavenPackDataProvider.redshift_user}:${DataProvider.RedshiftRavenPackDataProvider.redshift_pwd}
  redshift_service = ${DataProvider.RedshiftRavenPackDataProvider.redshift_endpoint}:${DataProvider.RedshiftRavenPackDataProvider.redshift_port}
  redshift_uri = "redshift+psycopg2://"${DataProvider.RedshiftRavenPackDataProvider.redshift_credentials}@${DataProvider.RedshiftRavenPackDataProvider.redshift_service}/${DataProvider.RedshiftRavenPackDataProvider.db_name}
}

DataProvider.HistoricalDataProviders {
  redshift_uri = "bigquery://"${gcp.project_id}/${gcp.default_dataset}
}

AnalyticsProcessing {
  gcp_project_id = ${GOOGLE_PROJECT_ID}

  S3AnalyticsInputDataIO {
    base_bucket = ${GOOGLE_PROJECT_ID}-${gcp.region}-dcm-subscriptions-prod,
    base_bucket = ${?ANALYTICS_S3_BASE_BUCKET}
    base_dir = "analytics_data",
    base_dir = ${?ANALYTICS_S3_BASE_LOCATION}
    input_prefix = "analytics_input",
    output_prefix = "analytics_output"
  }
  EfsHandler {
    base_dir = "analytics_data"
    input_prefix = "analytics_input",
    output_prefix = "analytics_output",
    base_location = "/mnt/efs/fs1",
    retention_period = "2B"
  }
  RedisNonPersistentCache {
    cluster_mode = False,
    host_server = "",
    port = 6379,
    db = 0
  }
  InMemoryNonPersistentCache {
    limit = 1000
  }
  AnalyticsMetadataHandlerRedis{
    cluster_mode = False
    cluster_mode = ${?REDIS_CLUSTER_MODE}
    db = 0
    host = "localhost"
	  host = ${?REDIS_HOST}
    port = 6379
  }
  AnalyticsMetadataHandlerSqlLite{
    db = "analytics_metadata.db"
    table = "subscriptions_analytics_processing_metadata"
  }
  AnalyticsRequestQueueInMemory {
    type = "deque"
  }
  AnalyticsRequestQueueSQS {
    # deprecated AWS configuration
  }
  AnalyticsRequestQueueGcpPub {
    queue_name = ""
    queue_name = ${?ANALYTICS_SQS_QUEUE_NAME}
  }
  AnalyticsRequestQueueGcpSub {
    queue_name = ""
    queue_name = ${?ANALYTICS_SQS_QUEUE_NAME}
  }
  AnalyticsRequestQueueGcpMonitoring {
  }
}

ParallelQueryRedshiftDownload {
  s3_default_location = gs://${gcp.project_id}-${gcp.region}-dcm-data-temp
  credentials {
    s3 {
      access_key = NoAWSKey
      secret_key = NoAWSSecret
    }
    redshift {
	host = marketdata-test.cq0v4ljf3cuw.us-east-1.redshift.amazonaws.com
	username = ${?REDSHIFT_USER}
	password = ${?REDSHIFT_PWD}
	database = dev
	port = 5439
    }
  }
}

# !!! PLEASE DO NOT ENABLE DATA PROVIDER HERE! SET THEM UP IN YOUR PERSONAL .intuition.conf FILE. THESE ARE HERE
# FOR REFERENCE

#DataProvider.HistoricalEquityDataProvider {
  #redshift_uri = ${DataProvider.RedshiftRavenPackDataProvider.redshift_uri}
#}

#DataProvider.H5HistoricalEquityDataProvider {
	#full_file_path = "./h5_historical_equity/historical_equities.h5",
	#cob_field = "Date",
	#df_name = "dataframe",
	#create_price_count = True
#}
#DataProvider.RedshiftDragonfishDataProvider {
  #redshift_uri = ${DataProvider.RedshiftRavenPackDataProvider.redshift_uri}
#}

#DataProvider.H5RavenpackDataProvider {
	#full_file_path = "./h5_historical_olmar/historical_ravenpack.h5",
	#cob_field = "Date",
	#df_name = "dataframe",
#}
#DataProvider.H5DragonfishDataProvider {
	#full_file_path = "./h5_dragonfish/dragonfish.h5",
	#cob_field = "Date",
	#df_name = "dataframe"
#}

DataProvider.KafkaOptionBarDataProvider {
	service_host = localhost
  service_port = 8080
  service_url = "http://"${DataProvider.KafkaOptionBarDataProvider.service_host}:${DataProvider.KafkaOptionBarDataProvider.service_port}"/"

  #kafka_host = ec2-54-147-151-149.compute-1.amazonaws.com
  kafka_host = broker-1.msk
  kafka_port = 9092
  kafka_host = ${?KAFKA_HOST}
  kafka_port = ${?KAFKA_PORT}
  kafka_bootstrap = ${DataProvider.KafkaOptionBarDataProvider.kafka_host}:${DataProvider.KafkaOptionBarDataProvider.kafka_port}

  absolute_missing_subjects_threshold = 123
  relative_missing_subjects_threshold = 0.85
  missing_subjects_time_before_trigger = 10
}


DataProvider.RealtimeRavenPackDataProvider {
  service_url = "http://subscription-service.k8s/ravenpack"
  kafka_host = broker-1.msk
  kafka_port = 9092
  # Let default kafka host/port be overridden by env vars, if present
  kafka_host = ${?KAFKA_HOST}
  kafka_port = ${?KAFKA_PORT}
  kafka_bootstrap = [broker-1.msk:9092, broker-2.msk:9092]
}
BrokerConnectionIB {
  # Live Trading
  # U1814262
  # paper DU229046, DU229048
  accounts = [U1814262]
  accounts_to_exclude = []
  account_list = []
  client_account_prefix = "U"
  advisor_account_prefix = "F"
  multi_thread_order_updates = true
  thread_time_interval_between_order_updates_in_secs = 10
  sleep_time_interval_for_manual_order_updates_in_sec = null
  waiting_time_for_positions_of_reconciliation_in_seconds = 60
  waiting_time_for_contract_details_request_in_seconds = 3600 #change back to 1800
  waiting_time_for_exec_details_of_reconciliation_in_seconds = 6000
  waiting_time_for_global_cancel_of_reconciliation_in_seconds = 20
  waiting_time_for_account_list = 5
  waiting_time_for_account_summary = 20
  waiting_time_for_replaceFA = 5
  max_number_retries_for_open_orders_before_mark_as_cancelled = 8
  commission_per_share_amount_for_longs = 0.005
  commission_per_share_amount_for_shorts = 0.0075
  min_commission_per_order = 1.0
  max_retries_account_list = 5
  max_retries_account_summary = 5
  max_retries_replaceFA = 5
}

TradingGroupsManagerIB {
  allow_default_account_for_trading = false
  default_account_for_trading = DU229049
}

LoopbackBrokerConnection {
  MockExecutor {
    slippage = 0.001
    commission_per_share = {1:0.005, -1:0.0075}
    min_commission = 1.0
    fill_mode = Full  # Full, NoFill, RandomFill, ConstantFill, RandomPartialFills, MaxVolumePerDay
    constant_fill_amount = null
    random_partial_fill_full_success_rate=0.3
    random_partial_fill_partial_fill_fraction=0.6,
    market_location = null
    max_market_volume_per_day=0.01
  }
  order_delay = "00:01:00"
}

DragonfishTrader {
  algorithm = Greeneye # One of Greeneye, Mooneye, Blueeye, Longfin, Shortfin, Triggerfish

}
ExecutionCoordinator {
  execution_styles_to_expert_map {
	OrderedAllOrNone = OrderedAllOrNoneWithCancellationExecutionExpert
	RebalanceVWAP = VWAPExecutionExpert
	HedgeCombo = NonGuaranteedComboLimitExecutionExpert
	AdaptiveAlgo = AdaptiveExecutionExpert
	MarketTimeLimit = MarketTimeLimitExecutionExpert
	LimitOrder = MarketTimeLimitExecutionExpert
  }
  default_execution_style = RebalanceVWAP
}

TWSIBReportRetriever {
  base_reporting_url = "https://gdcdyn.interactivebrokers.com/Universal/servlet/FlexStatementService"
  request_report_url = ${TWSIBReportRetriever.base_reporting_url}.SendRequest
  retrieve_report_url = ${TWSIBReportRetriever.base_reporting_url}.GetStatement
  ib_flex_query_no = 221563
  ib_reporting_token = ${?IB_TWS_REPORTING_TOKEN}
  max_wait_in_secs = 165
}

PositionReconciliationSOD_DCM_MS_SS {
  CASH_DISCREPANCY_TOLERANCE = 0.001
  MONEY_MARKET_SYMBOL = "MPFXX"
  MS_account_no = "038CDN808"
  MS_account_name = "DCM A.I. ABSOLUTE RETURN MASTER FUND LP"
  MS_custodian = "MSCO"
  MS_currency = "USD"
  MS_trading_name = "DATA CAPITAL MANAGEMENT"
  SS_fund_name = "DCM A.I. Absolute Return Master Fund LP DCMMST"
  SS_custodian = "MSCO"
  SS_currency = "USD"
  DCM_custodian = "MSCO"
  DCM_fund = "DCM_AI_AbsRet"
  DCM_account_type = "Prime"
  DCM_security_type = "Equity"
  DCM_currency = "USD"
  DCM_fx_rate = 1
}

SubscriptionsDataIO {
   gmu_instructions_models = gs://${gcp.project_id}-${gcp.region}-dcm-subscribers-data/gmu_instructions/models/
   gmu_instructions_subscriptions = gs://${gcp.project_id}-${gcp.region}-dcm-subscribers-data/gmu_instructions/subscriptions
}

CorporationAction {
   scrape_dividends = false
   scrape_splits = false
}
